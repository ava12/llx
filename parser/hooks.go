package parser

import (
	"context"
	"sync"

	"github.com/ava12/llx/grammar"
	"github.com/ava12/llx/lexer"
	"github.com/ava12/llx/source"
)

// TokenHook allows to perform additional actions when token is fetched from lexer, but before
// it is fed to parser, e.g. emit external $indent/$dedent tokens when text indentation changes,
// fetch complex lexemes (e.g. heredoc strings).
// emit flag set to true means that incoming token must be fed to parser,
// false means that it must be dropped.
// extra contains additional tokens that must be fed to parser after or instead of hooked one.
type TokenHook = func(ctx context.Context, token *Token, tc *TokenContext) (emit bool, extra []*Token, e error)

// NodeHookInstance receives notifications for node being processed by parser.
type NodeHookInstance interface {
	// NewNode is called before a child node is pushed on stack.
	// Receives child node name and its initial token.
	NewNode(node string, token *Token) error

	// HandleNode is called after nested node is finalized and dropped.
	// Receives child node name.
	// Receives result of closest nested hook EndNode() call or nil if none of nested nodes was hooked.
	HandleNode(node string, result any) error

	// HandleToken is called when a token belonging to current node is received.
	HandleToken(token *Token) error

	// EndNode is called before current node is finalized and dropped.
	// result is passed to parent node hook or returned as a parse result if current node is the root.
	EndNode() (result any, e error)
}

// NodeHook allows to perform actions on nodes emitted by parser. Called before new node is pushed.
// Receives node name and initial token.
type NodeHook = func(ctx context.Context, node string, token *Token, nc *NodeContext) (NodeHookInstance, error)

type defaultHookInstance struct {
	result any
}

func (dhi *defaultHookInstance) NewNode(node string, token *Token) error {
	return nil
}

func (dhi *defaultHookInstance) HandleNode(node string, result any) error {
	dhi.result = result
	return nil
}

func (dhi *defaultHookInstance) HandleToken(token *Token) error {
	return nil
}

func (dhi *defaultHookInstance) EndNode() (result any, e error) {
	return dhi.result, nil
}

func defaultNodeHook(context.Context, string, *Token, *NodeContext) (NodeHookInstance, error) {
	return &defaultHookInstance{}, nil
}

// Special token type names used by token hooks.
const (
	// AnyToken means any token type defined in grammar, not counting EoF nor EoI special tokens.
	AnyToken = ""
	// EofToken means special end-of-file token emitted after the end of source file.
	EofToken = lexer.EofTokenName
	// EoiToken means special end-of-input token emitted right after the EoF token of the last source file.
	EoiToken = lexer.EoiTokenName // end-of-input token
)

// AnyNode denotes any node, used by node hooks.
const AnyNode = ""

const anyOffset = -1

type TokenHooks map[string]TokenHook
type NodeHooks map[string]NodeHook

// Hooks contains all token and node hooks used in parsing process.
// Default action when no suitable token hook found is to use token as is.
type Hooks struct {
	// Tokens contains hooks for different token types. Key is either token type name or AnyToken constant.
	// AnyToken hook is a fallback.
	Tokens TokenHooks

	// Literals contains hooks for tokens with specific content. Key is token content.
	// These hooks have top priority (if token type allows matching against literals).
	Literals TokenHooks

	// Nodes contains hooks for nodes. Key is either node name or AnyNode constant.
	// AnyNode hook is a fallback.
	Nodes NodeHooks
}

// TokenContext contains methods that may be useful for token hooks.
type TokenContext struct {
	pc           *ParseContext
	layer        int
	peekDistance int
	snap         source.QueueSnapshot
	tokenFetched bool
}

func (tc *TokenContext) ParseContext() *ParseContext {
	return tc.pc
}

// PeekToken allows token hook to look ahead one or more tokens without affecting parser.
// Each call returns different token, starting with extra tokens generated by upper hook layers,
// followed by tokens fetched from sources. E.g. if upper layers generated extra tokens "foo" and "bar",
// and source contains tokens "baz" and "qux", then sequential calls of PeekToken() will return
// "foo", then "bar", then "baz", then "qux".
// Parse context is restored when token hook returns result, as if PeekToken was never called.
// Returns nil token and error when lexer returns error.
// NB: this feature interferes with ambiguous token fetching and token hooks:
// this method tries to fetch any token from any group, and fetched tokens are not handled by hooks.
func (tc *TokenContext) PeekToken() (*Token, error) {
	pc := tc.pc
	if tc.tokenFetched {
		return pc.fetchToken(lexer.AllTokenTypes)
	}

	distance := tc.peekDistance
	tc.peekDistance++
	for layer := tc.layer + 1; layer < len(pc.tokenHooks); layer++ {
		l := pc.tokenHooks[layer].tokens.Len()
		if distance < l {
			tok, _ := pc.tokenHooks[layer].tokens.Peek(distance)
			return tok, nil
		}

		distance -= l
	}

	tc.snap = pc.sources.Snapshot()
	tc.tokenFetched = true
	return pc.fetchToken(lexer.AllTokenTypes)
}

func (tc *TokenContext) restore() {
	if tc.tokenFetched {
		tc.pc.sources.Restore(tc.snap)
		tc.tokenFetched = false
	}
	tc.peekDistance = 0
}

// NodeContext contains methods that may be useful for node hooks.
type NodeContext struct {
	pc *ParseContext
}

func (nc *NodeContext) ParseContext() *ParseContext {
	return nc.pc
}

// NodeStack returns list of stacked node names.
// The first element is the current node being processed, and the last one is the root.
func (nc *NodeContext) NodeStack() []string {
	nodes := nc.pc.parser.grammar.Nodes
	indexes := nc.pc.nodeStack.Indexes()
	result := make([]string, len(indexes))
	for i, index := range indexes {
		result[i] = nodes[index].Name
	}

	return result
}

// HookLayer is a token/node hook layer configured for specific grammar.
type HookLayer interface {
	// Init is called for each layer when parsing context is created but before parsing is started.
	Init(ctx context.Context, pc *ParseContext) Hooks
}

// HookLayerTemplate is used to create hook layers for different grammars.
type HookLayerTemplate interface {
	// Setup is called for every hook layer used by specific grammar.
	Setup(commands []grammar.LayerCommand, p *Parser) (HookLayer, error)
}

var (
	knownHookLayers    = map[string]HookLayerTemplate{}
	knownHookLayerLock sync.RWMutex
)

// RegisterHookLayer registers named hook layer template that can be referred by grammar.
// Returns ErrLayerRegistered if layer template with this name is already registered.
func RegisterHookLayer(name string, tpl HookLayerTemplate) error {
	knownHookLayerLock.Lock()
	defer knownHookLayerLock.Unlock()

	_, has := knownHookLayers[name]
	if has {
		return layerRegisteredError(name)
	}

	knownHookLayers[name] = tpl
	return nil
}
